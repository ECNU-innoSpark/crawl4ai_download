# =============================================================================
# NeurIPS 论文爬取一键配置
# =============================================================================
# 
# 使用方法:
#   python run_nips.py                  # 运行所有启用的任务
#   python run_nips.py --crawl-only     # 只运行爬虫任务
#   python run_nips.py --capture-only   # 只运行截图任务
#   python run_nips.py --download-only  # 只运行下载任务
#   python run_nips.py --task 1         # 只运行第1个爬虫任务
#   python run_nips.py --task 1,2       # 只运行第1、2个爬虫任务
#
# 工作流程:
#   Level 1: papers.nips.cc/ → 获取年份链接 → nips_level1_years.jsonl
#   Level 2: 各年份页面 → 获取论文链接 → nips_level2_papers.jsonl
#
# =============================================================================

# =============================================================================
# 全局配置（所有任务共享）
# =============================================================================
global:
  # 浏览器配置
  browser:
    headless: false                   # true: 无头模式（后台运行）
                                      # false: 显示浏览器窗口（首次运行建议 false，便于手动通过验证）
    verbose: true                     # 是否输出详细日志
  
  # 爬取配置
  crawler:
    timeout: 120000                   # 页面加载超时时间（毫秒），120000 = 2分钟
    wait_until: "load"                # 等待策略: 
                                      #   - "domcontentloaded": DOM 加载完成
                                      #   - "load": 页面完全加载
                                      #   - "networkidle": 网络空闲
    delay_before_return: 10.0         # 返回 HTML 前等待时间（秒），用于等待动态内容加载
  
  # 日志配置
  logging:
    level: "INFO"                     # 日志级别: DEBUG, INFO, WARNING, ERROR
    format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  
  # 缓存配置
  cache_path: "./.crawl4ai_cache"     # 浏览器缓存和 cookies 存储路径

# =============================================================================
# 爬虫任务配置（按顺序执行）
# =============================================================================
# 每个任务可以使用上一个任务的输出文件作为输入
# enabled: true/false 控制是否执行该任务
# =============================================================================
crawl_tasks:
  # ---------------------------------------------------------------------------
  # 第一步：爬取 NeurIPS 主页，获取所有年份链接
  # ---------------------------------------------------------------------------
  - name: "Level 1 - 获取年份列表"
    enabled: true                     # 是否启用此任务
    target_url: "https://papers.nips.cc/"   # 目标 URL（也可以是 .jsonl 文件路径）
    regex_pattern: '^https://papers\.nips\.cc/paper_files/paper/\d{4}/?$'
                                      # URL 过滤正则表达式
                                      # 此正则匹配: https://papers.nips.cc/paper_files/paper/2024/
    output_file: "nips_level1_years.jsonl"  # 输出文件名
    click_selector: ""                # CSS 选择器，用于点击展开页面（留空不点击）
    max_clicks: 0                     # 最大点击次数（0 表示不点击）
    jsonl_input:                      # JSONL 输入配置（当 target_url 是 .jsonl 文件时生效）
      url_field: "matched_url"        # 从 JSONL 中读取 URL 的字段名
      delay_between_urls: 2.0         # 每个 URL 之间的延迟（秒）
  
  # ---------------------------------------------------------------------------
  # 第二步：爬取每个年份页面，获取论文列表
  # ---------------------------------------------------------------------------
  - name: "Level 2 - 获取论文列表"
    enabled: true
    target_url: "nips_level1_years.jsonl"   # 使用上一步的输出作为输入！
    regex_pattern: 'https://papers\.nips\.cc/paper_files/paper/\d{4}/hash/[a-f0-9]+-Abstract(-Conference)?\.html'
                                      # 匹配论文摘要页面链接
    output_file: "nips_level2_papers.jsonl"
    click_selector: ""
    max_clicks: 0
    jsonl_input:
      url_field: "matched_url"
      delay_between_urls: 3.0         # 每个年份页面间隔 3 秒，避免请求过快
  
  # # ---------------------------------------------------------------------------
  # # 第三步：爬取每篇论文详情页，获取 PDF 链接（可选）
  # # ---------------------------------------------------------------------------
  # - name: "Level 3 - 获取论文详情"
  #   enabled: false                    # 默认禁用，需要时改为 true
  #   target_url: "nips_level2_papers.jsonl"
  #   regex_pattern: 'https://papers\.nips\.cc/paper_files/paper/\d{4}/file/.*\.pdf'
  #                                     # 匹配 PDF 下载链接
  #   output_file: "nips_level3_pdfs.jsonl"
  #   click_selector: ""
  #   max_clicks: 0
  #   jsonl_input:
  #     url_field: "matched_url"
  #     delay_between_urls: 2.0

# =============================================================================
# 页面截图配置（可选）
# =============================================================================
# 用于保存页面截图和 HTML，便于离线查看或存档
# =============================================================================
capture_task:
  enabled: false                      # 设为 true 启用截图任务
  input: "nips_level2_years.jsonl"    # 输入: JSONL 文件路径 或 单个 URL
  url_field: "matched_url"            # JSONL 中的 URL 字段名
  output_dir: "./captures_nips"       # 截图和 HTML 保存目录
  output_file: "nips_capture_results.jsonl"  # 结果记录文件
  save_screenshot: true               # 是否保存截图
  save_html: true                     # 是否保存 HTML
  screenshot:
    full_page: true                   # true: 截取整个页面 / false: 只截取可视区域
    format: "png"                     # 截图格式: png, jpeg
    max_height: 30000                 # 最大截图高度（像素），超过则分段截图
  request_delay: 2.0                  # 每个 URL 之间的延迟（秒）
  page_load_timeout: 60000            # 页面加载超时（毫秒）
  wait_after_load: 3.0                # 页面加载后等待时间（秒）
  max_retries: 2                      # 失败重试次数

# =============================================================================
# PDF 下载配置（可选）
# =============================================================================
# 用于下载论文 PDF 文件
# =============================================================================
download_task:
  enabled: false                      # 设为 true 启用下载任务
  input: "nips_level2_pdfs.jsonl"     # 输入: JSONL 文件路径 或 单个 URL
  url_field: "matched_url"            # JSONL 中的 URL 字段名
  output_file: "nips_download_results.jsonl"  # 下载结果记录文件
  download_dir: "./downloads_nips"    # PDF 保存目录（按年份分类）
  max_concurrent: 2                   # 最大并发下载数（建议 1-3，避免被封）
  request_delay: 3.0                  # 每次请求间隔（秒）
  download_timeout: 120               # 下载超时时间（秒）
  max_retries: 3                      # 失败重试次数
  retry_delay: 10.0                   # 重试等待时间（秒）
  pdf_patterns:                       # PDF 链接匹配正则（用于从页面提取 PDF 链接）
    - 'https://papers\.nips\.cc/paper_files/paper/\d{4}/file/[a-f0-9]+-Paper(-Conference)?\.pdf'
  year_patterns:                      # 年份提取正则（用于按年份分类存储）
    - '/paper/(\d{4})/'
  default_year: "Unknown"             # 无法提取年份时使用的默认值
