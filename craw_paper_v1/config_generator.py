"""
ä½¿ç”¨ LLM è‡ªåŠ¨ç”Ÿæˆçˆ¬è™«é…ç½®
"""
import asyncio
import yaml
from pathlib import Path
from typing import Dict, Any, Optional
from openai import AsyncOpenAI


class ConfigGenerator:
    """LLM é…ç½®ç”Ÿæˆå™¨"""
    
    def __init__(self, config_path: str = "config.yaml"):
        self.config_path = Path(config_path)
        self.config = self._load_config()
        self.client = None
        
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        if self.config_path.exists():
            with open(self.config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        return {}
    
    def _init_client(self):
        """åˆå§‹åŒ– LLM å®¢æˆ·ç«¯"""
        if not self.client:
            llm_config = self.config.get('llm', {})
            self.client = AsyncOpenAI(
                api_key=llm_config.get('api_key'),
                base_url=llm_config.get('base_url')
            )
    
    async def analyze_website(self, url: str, sample_html: str = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨ LLM åˆ†æç½‘ç«™ç»“æ„å¹¶ç”Ÿæˆé…ç½®
        
        Args:
            url: ç½‘ç«™ URL
            sample_html: ç¤ºä¾‹ HTMLï¼ˆå¯é€‰ï¼‰
        
        Returns:
            ç”Ÿæˆçš„é…ç½®å­—å…¸
        """
        self._init_client()
        
        prompt = self._build_analysis_prompt(url, sample_html)
        
        llm_config = self.config.get('llm', {})
        response = await self.client.chat.completions.create(
            model=llm_config.get('model', 'gpt-4'),
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ç²¾é€šç½‘é¡µç»“æ„åˆ†æå’Œæ­£åˆ™è¡¨è¾¾å¼çš„çˆ¬è™«ä¸“å®¶ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=llm_config.get('temperature', 0.3),
            max_tokens=llm_config.get('max_tokens', 16384)  # å¢åŠ åˆ° 4000
        )
        
        result_text = response.choices[0].message.content.strip()
        
        # è§£æ LLM è¿”å›çš„é…ç½®
        config_data = self._parse_llm_response(result_text)
        
        return config_data
    
    def _build_analysis_prompt(self, url: str, sample_html: str = None) -> str:
        """æ„å»ºåˆ†ææç¤ºè¯"""
        prompt = f"""# Role
ä½ æ˜¯ä¸€ä½ç²¾é€šè‡ªåŠ¨åŒ–æ•°æ®é‡‡é›†çš„èµ„æ·±çˆ¬è™«å·¥ç¨‹å¸ˆï¼Œæ“…é•¿åˆ†æå¤æ‚ç½‘ç«™çš„ URL æ‹“æ‰‘ç»“æ„ï¼Œå¹¶èƒ½ç¼–å†™é«˜ç²¾åº¦çš„æ­£åˆ™è¡¨è¾¾å¼ã€‚

# Task
è¯·åˆ†æç›®æ ‡ç½‘ç«™ {url} çš„ç»“æ„ï¼Œå¹¶æŒ‰ç…§é€’å½’çˆ¬å–çš„é€»è¾‘ç”Ÿæˆä¸€ä»½ YAML æ ¼å¼çš„å±‚çº§é…ç½®ã€‚

# Analysis Strategy
1. **æ‹“æ‰‘åˆ†æ**ï¼šè¯†åˆ«ç½‘ç«™ä»â€œå…¥å£â€åˆ°â€œæœ€ç»ˆPDFæ–‡ä»¶â€çš„é€»è¾‘è·¯å¾„ï¼ˆé€šå¸¸ä¸ºï¼šä¸»é¡µ -> åˆ†ç±»/å¹´ä»½åˆ—è¡¨ -> è®ºæ–‡åˆ—è¡¨é¡µ -> æ‘˜è¦è¯¦æƒ…é¡µ -> PDFä¸‹è½½é“¾æ¥ï¼‰ã€‚
2. **æ­£åˆ™ç²¾åº¦**ï¼šæå–æ¨¡å¼ (extract_pattern) åº”å°½å¯èƒ½æ•è·æ½œåœ¨é“¾æ¥ï¼›è¿‡æ»¤æ¨¡å¼ (filter_pattern) å¿…é¡»ä½¿ç”¨é”šç‚¹ï¼ˆå¦‚ ^ å’Œ $ï¼‰ç¡®ä¿è·¯å¾„çº¯å‡€ï¼Œæ’é™¤æ— ç”¨çš„å‚æ•°æˆ–éç›®æ ‡æ–‡ä»¶ã€‚
3. **è·¯å¾„å…¼å®¹**ï¼šéœ€åŒæ—¶è€ƒè™‘ç»å¯¹è·¯å¾„ (https://...) å’Œç›¸å¯¹è·¯å¾„ (/paper_files/...) çš„åŒ¹é…ã€‚

# Output Format (YAML)
```yaml
levels:
  - level: 1
    name: "èµ·å§‹é¡µ/ç´¢å¼•é¡µ"
    url_pattern: "åŒ¹é…å½“å‰å±‚çº§çš„æ­£åˆ™è¡¨è¾¾å¼"
    extract_pattern: "æå–ä¸‹ä¸€çº§é“¾æ¥çš„æ­£åˆ™ (éœ€æ•è·å…³é”®è·¯å¾„ç‰¹å¾)"
    filter_pattern: "è¿‡æ»¤æ­£åˆ™ (ç¡®ä¿åªä¿ç•™ä¸‹ä¸€çº§ç›®æ ‡çš„åˆæ³•URL)"
    description: "æè¿°å½“å‰å±‚çº§çš„ç‰¹å¾åŠè·³è½¬é€»è¾‘"

  - level: n (ä»¥æ­¤ç±»æ¨ï¼Œç›´åˆ°æœ€ç»ˆ PDF é“¾æ¥å±‚)
    name: "PDF ä¸‹è½½å±‚"
    url_pattern: "åŒ¹é… PDF æ‰€åœ¨é¡µé¢çš„æ­£åˆ™"
    extract_pattern: "æå– .pdf ç»“å°¾çš„é“¾æ¥æ­£åˆ™"
    filter_pattern: "è¿‡æ»¤æ­£åˆ™ (æ’é™¤ Metadata, Bibtex ç­‰å¹²æ‰°é¡¹)"
    description: "æè¿°å¦‚ä½•è·å–æœ€ç»ˆçš„ PDF åŸå§‹æ–‡ä»¶"
"""
        
        if sample_html:
            prompt += f"\nç¤ºä¾‹ HTML ç‰‡æ®µï¼š\n```html\n{sample_html}\n```\n"
        
        prompt += "\nè¯·ç›´æ¥è¿”å› YAML æ ¼å¼çš„é…ç½®ï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚"
        
        return prompt
    
    def _parse_llm_response(self, response: str) -> Dict[str, Any]:
        """è§£æ LLM è¿”å›çš„é…ç½®"""
        # å°è¯•æå– YAML ä»£ç å—
        import re
        yaml_match = re.search(r'```ya?ml\s*\n(.*?)\n```', response, re.DOTALL)
        if yaml_match:
            yaml_content = yaml_match.group(1)
        else:
            yaml_content = response
        
        try:
            config_data = yaml.safe_load(yaml_content)
            return config_data
        except yaml.YAMLError as e:
            print(f"âš ï¸  YAML è§£æå¤±è´¥: {e}")
            print(f"LLM è¿”å›å†…å®¹:\n{response}")
            return {}
    
    def update_config(self, new_config: Dict[str, Any], merge: bool = True):
        """
        æ›´æ–°é…ç½®æ–‡ä»¶
        
        Args:
            new_config: æ–°é…ç½®
            merge: æ˜¯å¦åˆå¹¶ï¼ˆTrueï¼‰æˆ–è¦†ç›–ï¼ˆFalseï¼‰
        """
        if merge and self.config:
            # åˆå¹¶é…ç½®
            self._deep_update(self.config, new_config)
        else:
            self.config = new_config
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(self.config_path, 'w', encoding='utf-8') as f:
            yaml.dump(self.config, f, allow_unicode=True, default_flow_style=False, indent=2)
        
        print(f"âœ… é…ç½®å·²æ›´æ–°: {self.config_path}")
    
    def _deep_update(self, base: Dict, update: Dict):
        """æ·±åº¦æ›´æ–°å­—å…¸"""
        for key, value in update.items():
            if isinstance(value, dict) and key in base and isinstance(base[key], dict):
                self._deep_update(base[key], value)
            else:
                base[key] = value


async def generate_config_from_url(url: str, config_path: str = "config.yaml"):
    """
    ä» URL ç”Ÿæˆé…ç½®çš„ä¾¿æ·å‡½æ•°
    
    Args:
        url: ç›®æ ‡ç½‘ç«™ URL
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
    """
    generator = ConfigGenerator(config_path)
    
    print(f"ğŸ¤– æ­£åœ¨ä½¿ç”¨ LLM åˆ†æç½‘ç«™: {url}")
    
    # é¦–å…ˆçˆ¬å–ç½‘ç«™è·å–ç¤ºä¾‹ HTML
    try:
        from crawl4ai import AsyncWebCrawler
        async with AsyncWebCrawler(verbose=False) as crawler:
            result = await crawler.arun(url=url, bypass_cache=True)
            if result.success:
                sample_html = result.html  # å–å‰5000å­—ç¬¦
                print("âœ… ç½‘ç«™çˆ¬å–æˆåŠŸï¼Œå¼€å§‹åˆ†æ...")
            else:
                sample_html = None
                print("âš ï¸  ç½‘ç«™çˆ¬å–å¤±è´¥ï¼Œä½¿ç”¨æ— ç¤ºä¾‹åˆ†æ...")
    except Exception as e:
        print(f"âš ï¸  çˆ¬å–å‡ºé”™: {e}ï¼Œä½¿ç”¨æ— ç¤ºä¾‹åˆ†æ...")
        sample_html = None
    
    # ä½¿ç”¨ LLM åˆ†æ
    config_data = await generator.analyze_website(url, sample_html)
    
    if config_data:
        # æ›´æ–°é…ç½®
        generator.update_config({'target': config_data}, merge=True)
        print("ğŸ‰ é…ç½®ç”Ÿæˆå®Œæˆï¼")
    else:
        print("âŒ é…ç½®ç”Ÿæˆå¤±è´¥")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨ LLM è‡ªåŠ¨ç”Ÿæˆçˆ¬è™«é…ç½®æ–‡ä»¶",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åˆ†æç½‘ç«™å¹¶ç”Ÿæˆé…ç½®
  python config_generator.py --url https://papers.nips.cc/
  
  # æŒ‡å®šè¾“å‡ºé…ç½®æ–‡ä»¶
  python config_generator.py --url https://example.com --output custom_config.yaml
  
  # ä½¿ç”¨è‡ªå®šä¹‰ API
  python config_generator.py --url https://example.com --api-key sk-xxx --model gpt-4
        """
    )
    
    parser.add_argument(
        '--url',
        type=str,
        default='https://papers.nips.cc/',
        help='è¦åˆ†æçš„ç½‘ç«™ URL'
    )
    
    parser.add_argument(
        '--output',
        type=str,
        default='config1.yaml',
        help='è¾“å‡ºé…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config.yaml)'
    )
    
    parser.add_argument(
        '--api-key',
        type=str,
        default="sk-eEHuvDfMPJf3mKQOmdDVHDq30RsA9RXKd4LhUtGxNgiXYtPq",
        help='OpenAI API Keyï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰'
    )
    
    parser.add_argument(
        '--base-url',
        type=str,
        default="http://49.51.37.239:3006/v1",
        help='API Base URLï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰'
    )
    
    parser.add_argument(
        '--model',
        type=str,
        default="gemini-3-pro-preview-thinking",
        help='æ¨¡å‹åç§°ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰'
    )
    
    args = parser.parse_args()
    
    # å¦‚æœæä¾›äº† API å‚æ•°ï¼Œæ›´æ–°é…ç½®
    if args.api_key or args.base_url or args.model:
        import yaml
        from pathlib import Path
        
        config_path = Path(args.output)
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f) or {}
        else:
            config = {}
        
        if 'llm' not in config:
            config['llm'] = {}
        
        if args.api_key:
            config['llm']['api_key'] = args.api_key
        if args.base_url:
            config['llm']['base_url'] = args.base_url
        if args.model:
            config['llm']['model'] = args.model
        
        # ä¿å­˜æ›´æ–°çš„é…ç½®
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, allow_unicode=True, default_flow_style=False, indent=2)
    
    asyncio.run(generate_config_from_url(args.url, args.output))
